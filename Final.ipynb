{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducción de datos con Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10000\n",
    "df_chunk = pd.read_csv('train.csv', chunksize=size)\n",
    "\n",
    "df_empty = pd.DataFrame()\n",
    "for chunk in df_chunk:\n",
    "    \n",
    "    df_empty = df_empty.append(chunk.sample(n=79))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#header = True\n",
    "#df_empty.to_csv('chunkP4.csv', header=header, mode='a')\n",
    "#header = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('chunkP4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datos vacíos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulos= dataset.isnull().sum()\n",
    "nulos[0:74]\n",
    "\n",
    "total_cells = np.product(dataset.shape)\n",
    "print (total_cells)\n",
    "\n",
    "total_missing = nulos.sum()\n",
    "print (total_missing)\n",
    "\n",
    "(float (total_missing)/total_cells)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(dataset.loc[dataset['orig_destination_distance'].notnull()]['orig_destination_distance'])\n",
    "#sns.countplot(dataset.loc[dataset['orig_destination_distance'].notnull()]['orig_destination_distance'])\n",
    "\n",
    "#dataset['Age'].fillna((dataset['Age'].mean()), inplace=True) # Data without outliers\n",
    "dataset['orig_destination_distance'].fillna((dataset['orig_destination_distance'].median()), inplace=True) # Data with outliers\n",
    "#dataset['catCluster'].fillna((dataset['catCluster'].median()), inplace=True) # Data with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulos= dataset.isnull().sum()\n",
    "nulos[0:74]\n",
    "\n",
    "total_cells = np.product(dataset.shape)\n",
    "print (total_cells) \n",
    "\n",
    "total_missing = nulos.sum()\n",
    "print (total_missing)\n",
    "\n",
    "(float (total_missing)/total_cells)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datosVacios = dataset.loc[dataset['hotel_cluster']]['orig_destination_distance'].mean()\n",
    "dataset.loc[(dataset['orig_destination_distance'].isnull()) & (dataset['hotel_cluster']), 'orig_destination_distance'] = datosVacios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10)) \n",
    "plt.title(\"Hotel Cluster\", fontsize = 25,loc = 'center', pad = 20)\n",
    "\n",
    "dataset.loc[(dataset['hotel_cluster'] < 20), 'catCluster'] = 1\n",
    "dataset.loc[(dataset['hotel_cluster'] > 20) & (dataset['hotel_cluster'] < 40), 'catCluster'] = 2\n",
    "dataset.loc[(dataset['hotel_cluster'] > 40) & (dataset['hotel_cluster'] < 60), 'catCluster'] = 3\n",
    "dataset.loc[(dataset['hotel_cluster'] > 60) & (dataset['hotel_cluster'] < 80), 'catCluster'] = 4\n",
    "dataset.loc[(dataset['hotel_cluster'] > 80), 'catCluster'] = 5\n",
    "\n",
    "sns.countplot(dataset['catCluster'])\n",
    "\n",
    "#sns.countplot(dataset['hotel_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Site name\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.countplot(dataset['site_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Site name\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.countplot(x=\"site_name\", hue=\"is_booking\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformación de las columnas srch_ci y srch_co, de esta forma se trabajará con la columna 'mes' para ver las temporadas.\n",
    "dataset['srch_ci'] = pd.to_datetime(dataset['srch_ci'])\n",
    "\n",
    "dataset['ci_day'] = dataset[\"srch_ci\"].apply(lambda x: x.day)\n",
    "dataset['ci_month'] = dataset[\"srch_ci\"].apply(lambda x: x.month)\n",
    "#dataset['ci_year'] = dataset[\"srch_ci\"].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Month\", fontsize = 25,loc = 'center', pad = 40)\n",
    "sns.countplot(x=\"ci_month\", order=list(range(1, 13)), data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Day\", fontsize = 25,loc = 'center', pad = 40)\n",
    "sns.countplot(x=\"ci_day\", order=list(range(1, 32)), data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Month & Package\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.countplot(x=\"ci_month\", hue=\"is_package\", order=list(range(1, 13)), data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['srch_co'] = pd.to_datetime(dataset['srch_co'])\n",
    "\n",
    "#dataset['co_day'] = dataset[\"srch_ci\"].apply(lambda x: x.day)\n",
    "dataset['co_month'] = dataset[\"srch_ci\"].apply(lambda x: x.month)\n",
    "#dataset['co_year'] = dataset[\"srch_ci\"].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10)) \n",
    "plt.title(\"Hotel Continent\", fontsize = 25,loc = 'center', pad = 20)\n",
    "\n",
    "sns.countplot(dataset['hotel_continent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10)) \n",
    "plt.title(\"Favorite Continent\", fontsize = 25,loc = 'center', pad = 20)\n",
    "\n",
    "sns.countplot(dataset['posa_continent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Diference\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.countplot(x=\"hotel_continent\", hue=\"posa_continent\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Mobile reservation\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.countplot(x=\"is_mobile\", hue=\"posa_continent\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Channel\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.countplot(x=\"channel\", order=list(range(0, 10)), data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Booiking by mobile\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.countplot(x=\"is_mobile\", hue=\"is_booking\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Destination Type\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.countplot(x=\"srch_destination_type_id\", hue=\"posa_continent\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Adults\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "#sns.countplot(x=\"srch_adults_cnt\", hue=\"is_booking\", data=dataset)\n",
    "sns.countplot(x=\"srch_children_cnt\", order=list(range(0, 10)), data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Children\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.countplot(x=\"srch_children_cnt\", hue=\"is_booking\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Package\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.countplot(x=\"is_package\", hue=\"is_booking\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Hotel rooms\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "#sns.countplot(x=\"srch_rm_cnt\", hue=\"is_booking\", data=dataset)\n",
    "sns.countplot(dataset['srch_rm_cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10))\n",
    "plt.title(\"Similar events\", fontsize = 25,loc = 'center', pad = 40)\n",
    "\n",
    "sns.barplot(x=\"cnt\", y=\"is_booking\", data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,10)) \n",
    "plt.title(\"hotel_country\", fontsize = 25,loc = 'center', pad = 20)\n",
    "\n",
    "dataset.loc[(dataset['hotel_country'] < 20), 'country'] = \"20\"\n",
    "dataset.loc[(dataset['hotel_country'] > 20) & (dataset['hotel_country'] < 40), 'country'] = \"40\"\n",
    "dataset.loc[(dataset['hotel_country'] > 40) & (dataset['hotel_country'] < 60), 'country'] = \"60\"\n",
    "dataset.loc[(dataset['hotel_country'] > 60) & (dataset['hotel_country'] < 80), 'country'] = \"80\"\n",
    "dataset.loc[(dataset['hotel_country'] > 80), 'country'] = \"100\"\n",
    "\n",
    "sns.countplot(dataset.loc[dataset['hotel_country'].notnull()]['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,8))\n",
    "sns.boxplot(x=\"hotel_country\", data=dataset)\n",
    "dataset.loc[(dataset['hotel_country'] > 200)]\n",
    "index_NaN_age = list(dataset.loc[(dataset['hotel_country'] > 200)].index)\n",
    "dataset.drop(index_NaN_age, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,8))\n",
    "sns.boxplot(x=\"hotel_market\", data=dataset)\n",
    "dataset.loc[(dataset['hotel_market'] > 1500)]\n",
    "index_NaN_age = list(dataset.loc[(dataset['hotel_market'] > 1500)].index)\n",
    "dataset.drop(index_NaN_age, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,8))\n",
    "sns.boxplot(x=\"cnt\", data=dataset)\n",
    "dataset.loc[(dataset['cnt'] > 30)]\n",
    "index_NaN_age = list(dataset.loc[(dataset['cnt'] > 30)].index)\n",
    "dataset.drop(index_NaN_age, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,8))\n",
    "sns.boxplot(x=\"site_name\", data=dataset)\n",
    "dataset.loc[(dataset['site_name'] > 30)]\n",
    "index_NaN_age = list(dataset.loc[(dataset['site_name'] > 30)].index)\n",
    "dataset.drop(index_NaN_age, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,8))\n",
    "sns.boxplot(x=\"orig_destination_distance\", data=dataset)\n",
    "dataset.loc[(dataset['orig_destination_distance'] > 6000)]\n",
    "index_NaN_age = list(dataset.loc[(dataset['orig_destination_distance'] > 6000)].index)\n",
    "dataset.drop(index_NaN_age, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,8))\n",
    "sns.boxplot(x=\"user_location_region\", data=dataset)\n",
    "dataset.loc[(dataset['user_location_region'] > 750)]\n",
    "index_NaN_age = list(dataset.loc[(dataset['user_location_region'] > 750)].index)\n",
    "dataset.drop(index_NaN_age, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (20,8))\n",
    "sns.boxplot(x=\"user_location_country\", data=dataset)\n",
    "#dataset.loc[(dataset['user_location_country'] > 70) & (dataset['user_location_country'] < 60)]\n",
    "#index_NaN_age = list(dataset.loc[(dataset['user_location_country'] > 70) & (dataset['user_location_country'] < 60)].index)\n",
    "#dataset.drop(index_NaN_age, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# División del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = dataset['catCluster']\n",
    "feature_vector = dataset.drop(['catCluster', 'hotel_cluster', 'srch_ci', 'srch_co', 'date_time', 'user_id', 'orig_destination_distance'], axis = 1)\n",
    "\n",
    "feature_vector.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_transform = []\n",
    "\n",
    "feature_vector.loc[feature_vector['NAME_CONTRACT_TYPE'].isnull(), 'NAME_CONTRACT_TYPE'] = 0\n",
    "\n",
    "for column in columns_to_transform:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    feature_vector[column] = le.fit_transform(feature_vector[column])\n",
    "    \n",
    "feature_vector.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.96, svd_solver='full') \n",
    "\n",
    "# Model training\n",
    "pca.fit(feature_vector)\n",
    "\n",
    "# Model transformation\n",
    "new_feature_vector = pca.transform(feature_vector)\n",
    "\n",
    "# Model information:\n",
    "print('Model information:')\n",
    "print('Number of components elected: %s' % pca.n_components)\n",
    "print('New feature dimension: %s' % pca.n_components_)\n",
    "print('Variance of every feature: %s' % pca.explained_variance_ratio_)\n",
    "\n",
    "# First 10 rows of new feature vector\n",
    "print('New feature vector: %s' % new_feature_vector[:10])\n",
    "\n",
    "# Una dimension es la correcta según PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute subset selection with trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree = ExtraTreesClassifier()\n",
    "\n",
    "# Model training\n",
    "extra_tree.fit(feature_vector, targets)\n",
    "\n",
    "# Model information:\n",
    "print('Model information:')\n",
    "\n",
    "# display the relative importance of each attribute\n",
    "print('Importance of every feature: ' + str(extra_tree.feature_importances_))\n",
    "\n",
    "# If model was training before prefit = True\n",
    "model = SelectFromModel(extra_tree, prefit=True)\n",
    "\n",
    "# Model transformation\n",
    "new_feature_vector = model.transform(feature_vector)\n",
    "\n",
    "# First 10 rows of new feature vector\n",
    "print('New feature vector: ' + str(new_feature_vector[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalozación Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data standardization\n",
    "standardized_data = preprocessing.scale(feature_vector)\n",
    "\n",
    "# First 10 rows of new feature vector\n",
    "print('New feature vector: %s', standardized_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalización Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "min_max_scaler.fit(feature_vector)\n",
    "\n",
    "# Model information:\n",
    "print('Model information:')\n",
    "print('Data min: %s', min_max_scaler.data_min_)\n",
    "print('Data max: %s', min_max_scaler.data_max_)\n",
    "\n",
    "normalized_data = min_max_scaler.transform(feature_vector)\n",
    "\n",
    "# First 10 rows of new feature vector\n",
    "print('New feature vector: %s', normalized_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(feature_vector, targets, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Bagging Classifier\", \"AdaBoost Classifier\"]\n",
    "models = [\n",
    "        BaggingClassifier(\n",
    "            base_estimator=tree.DecisionTreeClassifier(\n",
    "                criterion='gini',\n",
    "                max_depth=10)\n",
    "        ),\n",
    "        AdaBoostClassifier(\n",
    "            base_estimator=tree.DecisionTreeClassifier(\n",
    "                criterion='gini',\n",
    "                max_depth=10)\n",
    "        )]\n",
    "\n",
    "for name, em_clf in zip(names, models):\n",
    "    print(\"###################---\" + name + \"---###################\")\n",
    "\n",
    "    em_clf.fit(X_train, Y_train)\n",
    "\n",
    "    # Model evaluation\n",
    "    test_data_predicted = em_clf.predict(X_test)\n",
    "    score = metrics.accuracy_score(Y_test, test_data_predicted)\n",
    "\n",
    "    print(\"Model Score: %s\", score)\n",
    "    print(\"Confusion Matrix:\")\n",
    "\n",
    "    print(metrics.confusion_matrix(Y_test, test_data_predicted))\n",
    "    \n",
    "    #Kappa Statistics\n",
    "    \n",
    "    print(\"Evaluation report\")\n",
    "\n",
    "    print(classification_report(Y_test, test_data_predicted))\n",
    "\n",
    "    print(\"Kappa Statistic: %s\" % (str(cohen_kappa_score(Y_test, test_data_predicted))))\n",
    "    \n",
    "    \n",
    "    #Cross Validation\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    score_array = []\n",
    "    score_array.append(score)\n",
    "\n",
    "    print(\"Cross Validation: %s\" %(str(np.average(score_array))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"MLP Classifier\", \"Random Forest Classifier\"]\n",
    "models = [\n",
    "        MLPClassifier(\n",
    "        hidden_layer_sizes=(50),\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\")\n",
    "    ,\n",
    "        RandomForestClassifier(\n",
    "            criterion='gini',\n",
    "            max_depth=10\n",
    "        )\n",
    "    ]\n",
    "\n",
    "for name, em_clf in zip(names, models):\n",
    "    print(\"###################---\" + name + \"---###################\")\n",
    "\n",
    "    em_clf.fit(X_train, Y_train)\n",
    "\n",
    "    # Model evaluation\n",
    "    test_data_predicted = em_clf.predict(X_test)\n",
    "    score = metrics.accuracy_score(Y_test, test_data_predicted)\n",
    "\n",
    "    print(\"Model Score: %s\", score)\n",
    "    print(\"Confusion Matrix:\")\n",
    "\n",
    "    print(metrics.confusion_matrix(Y_test, test_data_predicted))\n",
    "    \n",
    "    #Kappa Statistics\n",
    "    \n",
    "    print(\"Evaluation report\")\n",
    "\n",
    "    print(classification_report(Y_test, test_data_predicted))\n",
    "\n",
    "    print(\"Kappa Statistic: %s\" % (str(cohen_kappa_score(Y_test, test_data_predicted))))\n",
    "    \n",
    "    \n",
    "    #Cross Validation\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    score_array = []\n",
    "    score_array.append(score)\n",
    "\n",
    "    print(\"Cross Validation: %s\" %(str(np.average(score_array))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"DecisionTreeClassifier\", \"GaussianNB\"]\n",
    "models = [\n",
    "       \n",
    "        tree.DecisionTreeClassifier()\n",
    "    , \n",
    "        GaussianNB()\n",
    "    ]\n",
    "\n",
    "for name, em_clf in zip(names, models):\n",
    "    print(\"###################---\" + name + \"---###################\")\n",
    "\n",
    "    em_clf.fit(X_train, Y_train)\n",
    "\n",
    "    # Model evaluation\n",
    "    test_data_predicted = em_clf.predict(X_test)\n",
    "    score = metrics.accuracy_score(Y_test, test_data_predicted)\n",
    "\n",
    "    print(\"Model Score: %s\", score)\n",
    "    print(\"Confusion Matrix:\")\n",
    "\n",
    "    print(metrics.confusion_matrix(Y_test, test_data_predicted))\n",
    "    \n",
    "    #Kappa Statistics\n",
    "    \n",
    "    print(\"Evaluation report\")\n",
    "\n",
    "    print(classification_report(Y_test, test_data_predicted))\n",
    "\n",
    "    print(\"Kappa Statistic: %s\" % (str(cohen_kappa_score(Y_test, test_data_predicted))))\n",
    "    \n",
    "    \n",
    "    #Cross Validation\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "    score_array = []\n",
    "    score_array.append(score)\n",
    "\n",
    "    print(\"Cross Validation: %s\" %(str(np.average(score_array))))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
